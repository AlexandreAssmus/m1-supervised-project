{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nLexical functions' id :\\nOper1: ls:fr:lf:168\\nOper2: ls:fr:lf:190\\nOper3: ls:fr:lf:193\\nFunc0: ls:fr:lf:195\\nFunc1: ls:fr:lf:213\\nFunc2: ls:fr:lf:219\\nFunc3: ls:fr:lf:222\\nLabor12:\\nLabor13:\\n\\n\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Lexical functions' id :\n",
    "Oper1: ls:fr:lf:168\n",
    "Oper2: ls:fr:lf:190\n",
    "Oper3: ls:fr:lf:193\n",
    "Func0: ls:fr:lf:195\n",
    "Func1: ls:fr:lf:213\n",
    "Func2: ls:fr:lf:219\n",
    "Func3: ls:fr:lf:222\n",
    "Labor12: ls:fr:lf:224\n",
    "Labor13: ls:fr:lf:961\n",
    "Labpr21: ls:fr:lf:225\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 source            target\n",
      "402    ls:fr:node:26291  ls:fr:node:43932\n",
      "5394   ls:fr:node:27309  ls:fr:node:43932\n",
      "5528   ls:fr:node:27348  ls:fr:node:26434\n",
      "17679  ls:fr:node:30858  ls:fr:node:43932\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "current_dir = os.path.dirname(\"parsing_lf_verb.ipynb\")\n",
    "csv_path = os.path.join(current_dir, '..', '..', 'lexical-system-fr', 'ls-fr-V3', '15-lslf-rel.csv')\n",
    "df = pd.read_csv(csv_path, delimiter='\\t')\n",
    "filtered_df = df[df['lf'] == 'ls:fr:lf:225'] # Oper / Func / Labor\n",
    "result = filtered_df[['source', 'target']]\n",
    "output_path = os.path.join(current_dir, '..', 'result_Labor21.csv')\n",
    "result.to_csv(output_path, index=False)\n",
    "print(result)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 source            target source_lexname target_lexname\n",
      "332    ls:fr:node:26269  ls:fr:node:50447       allergie       souffrir\n",
      "395    ls:fr:node:26291  ls:fr:node:34765            ami           être\n",
      "418    ls:fr:node:26292  ls:fr:node:56691          amour          avoir\n",
      "419    ls:fr:node:26292  ls:fr:node:27370          amour       éprouver\n",
      "420    ls:fr:node:26292  ls:fr:node:56763          amour         porter\n",
      "...                 ...               ...            ...            ...\n",
      "64600  ls:fr:node:56701  ls:fr:node:50447         ictère       souffrir\n",
      "64602  ls:fr:node:56702  ls:fr:node:56691     étonnement          avoir\n",
      "64603  ls:fr:node:56702  ls:fr:node:27370     étonnement       éprouver\n",
      "64604  ls:fr:node:56702  ls:fr:node:29223     étonnement      ressentir\n",
      "64686  ls:fr:node:56760  ls:fr:node:56763       jugement         porter\n",
      "\n",
      "[813 rows x 4 columns]\n",
      "Les données enrichies ont été sauvegardées dans ../support_verb/lf_source_target/Oper1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Etudiant\\AppData\\Local\\Temp\\ipykernel_18408\\306590752.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result.loc[:, 'source_lexname'] = result['source'].map(id_to_lexname)\n",
      "C:\\Users\\Etudiant\\AppData\\Local\\Temp\\ipykernel_18408\\306590752.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result.loc[:, 'target_lexname'] = result['target'].map(id_to_lexname)\n"
     ]
    }
   ],
   "source": [
    "# Load csv file \n",
    "df = pd.read_csv('../../lexical-system-fr/ls-fr-V3/15-lslf-rel.csv', delimiter='\\t')  \n",
    "nodes_df = pd.read_csv('../../lexical-system-fr/ls-fr-V3/01-lsnodes.csv', delimiter='\\t')\n",
    "\n",
    "# Filtrer les lignes où la colonne 'lf' est égale à 'id de la lf'\n",
    "filtered_df = df[df['lf'] == 'ls:fr:lf:168'] # Oper / Func / Labor\n",
    "\n",
    "# Sélectionner les colonnes 'source' et 'target'\n",
    "result = filtered_df[['source', 'target']]\n",
    "nodes_df['lexname_cleaned'] = nodes_df['lexname'].str.extract(r'>\\s*(.+?)\\s*<')\n",
    "id_to_lexname = pd.Series(nodes_df.lexname_cleaned.values, index=nodes_df.id).to_dict()\n",
    "# Appliquer les correspondances aux colonnes 'source' et 'target' de result\n",
    "result.loc[:, 'source_lexname'] = result['source'].map(id_to_lexname)\n",
    "result.loc[:, 'target_lexname'] = result['target'].map(id_to_lexname)\n",
    "#result.to_csv('../support_verb/result_Labor21.csv', index=False)\n",
    "# Afficher les résultats\n",
    "print(result)\n",
    "# Sauvegarder le résultat enrichi dans un nouveau fichier CSV\n",
    "output_file = '../support_verb/lf_source_target/Oper1.csv'\n",
    "result.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Les données enrichies ont été sauvegardées dans\", output_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "If you want to use `CamembertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Écrire une phrase utilisant le nom 'haine' et le verbe 'inspirer':\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, CamembertTokenizer, CamembertModel\n",
    "\n",
    "def generate_text(source, verb):\n",
    "    # Initialiser le tokenizer et le modèle pour CamemBERT\n",
    "    tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
    "    model = CamembertModel.from_pretrained('camembert-base')\n",
    "    \n",
    "    # Charger le pipeline de génération de texte en utilisant CamemBERT\n",
    "    generator = pipeline('text-generation', model='camembert-base')\n",
    "\n",
    "    # Créer un prompt avec le nom et le verbe\n",
    "    prompt = f\"Écrire une phrase utilisant le nom '{source}' et le verbe '{verb}':\"\n",
    "\n",
    "    # Générer la réponse à partir du prompt en utilisant les tokens d'EOS comme pad_token_id\n",
    "    responses = generator(prompt, max_length=50, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    # Prendre la première réponse générée\n",
    "    generated_text = responses[0]['generated_text']\n",
    "    return generated_text.strip()\n",
    "\n",
    "# Exemple d'utilisation\n",
    "source_lexname = \"haine\"\n",
    "target_lexname = \"inspirer\"\n",
    "sentence = generate_text(source_lexname, target_lexname)\n",
    "print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Écrire une phrase en utilisant le nom 'haine' et le verbe 'inspirer': il se prêté se trouver les journaux que saur une personne de l'infrage à nût. Le voiture est même, il a jût, le verbe.\n",
      "\n",
      "Efrit-l-décor,\n",
      "\n",
      "'Décor-l-décor le faç\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, pipeline\n",
    "\n",
    "def generate_text(source, verb):\n",
    "    # Charger le tokenizer et le modèle GPT-2\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "    # Créer un pipeline de génération de texte avec GPT-2\n",
    "    text_generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "\n",
    "    # Créer un prompt avec le nom et le verbe\n",
    "    prompt = f\"Écrire une phrase en utilisant le nom '{source}' et le verbe '{verb}':\"\n",
    "\n",
    "    # Générer la réponse à partir du prompt\n",
    "    responses = text_generator(prompt, max_length=100, num_return_sequences=1)\n",
    "\n",
    "    # Prendre la première réponse générée\n",
    "    generated_text = responses[0]['generated_text']\n",
    "    return generated_text.strip()\n",
    "\n",
    "# Exemple d'utilisation\n",
    "source_lexname = \"haine\"\n",
    "target_lexname = \"inspirer\"\n",
    "sentence = generate_text(source_lexname, target_lexname)\n",
    "print(sentence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
